{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kamohelo99/C0S711_Assignment_3/blob/Ndumiso/Inference_and_Submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbJzYrZefe47"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "from scipy.spatial import cKDTree\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DRIVE_PATH = Path(\"/content/drive/MyDrive/assignmentdata\")\n",
        "DATA_DIR = DRIVE_PATH / \"data\"\n",
        "CHECKPOINT_DIR = DRIVE_PATH / \"checkpoints\"\n",
        "SPLIT_DIR = DRIVE_PATH / \"splits\"\n",
        "\n",
        "CHAMPION_MODEL_PATH = CHECKPOINT_DIR / 'semi_supervised_best_model.pth'\n",
        "CLASSES = (SPLIT_DIR / \"classes.txt\").read_text().splitlines()\n",
        "num_classes = len(CLASSES)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load the Champion Model\n",
        "def build_adapted_model(model_name=\"efficientnet_b0\", num_classes=num_classes):\n",
        "    model = models.get_model(model_name, weights=None) # No need for pre-trained weights\n",
        "    conv_layer = model.features[0][0]\n",
        "    new_conv = nn.Conv2d(1, conv_layer.out_channels, kernel_size=conv_layer.kernel_size, stride=conv_layer.stride, padding=conv_layer.padding, bias=(conv_layer.bias is not None))\n",
        "    model.features[0][0] = new_conv\n",
        "    in_features = model.classifier[1].in_features\n",
        "    model.classifier = nn.Sequential(nn.Dropout(p=0.3), nn.Linear(in_features, num_classes))\n",
        "    return model\n",
        "\n",
        "model = build_adapted_model()\n",
        "model.load_state_dict(torch.load(CHAMPION_MODEL_PATH, map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "print(\"Champion semi-supervised model loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions for inference\n",
        "def extract_coords_from_filename(fname: str):\n",
        "  \"\"\"Extract RA/Dec from filename using a robust regex.\"\"\"\n",
        "  pattern = r\"([-+]?\\d*\\.\\d+|\\d+)\\s+([-+]?\\d*\\.\\d+|\\d+)_\"\n",
        "  m = re.search(pattern, fname)\n",
        "  if m:\n",
        "    try:\n",
        "      return float(m.group(1)), float(m.group(2))\n",
        "    except (ValueError, IndexError):\n",
        "      return None, None\n",
        "  return None, None\n",
        "\n",
        "class InferenceDataset(Dataset):\n",
        "    def __init__(self, file_list, transform):\n",
        "        self.files = file_list; self.transform = transform\n",
        "    def __len__(self): return len(self.files)\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.files[idx]).convert('L')\n",
        "        return self.transform(img), self.files[idx]\n",
        "\n",
        "# Main Logic for test_labels.csv\n",
        "print(\"\\nGenerating test_labels.csv ---\")\n",
        "\n",
        "# Build a KD-tree of ALL images for fast matching\n",
        "all_imgs = []\n",
        "for folder in [\"typ/typ_PNG\", \"exo/exo_PNG\", \"unl/unl_PNG\"]:\n",
        "    folder_path = DRIVE_PATH / folder\n",
        "    if not folder_path.exists(): continue\n",
        "    for fpath in folder_path.glob(\"*.png\"):\n",
        "        ra, dec = extract_coords_from_filename(fpath.name)\n",
        "        if ra is not None: all_imgs.append({\"image_path\": str(fpath), \"ra\": ra, \"dec\": dec})\n",
        "img_df = pd.DataFrame(all_imgs)\n",
        "kdtree = cKDTree(img_df[['ra', 'dec']].values)\n",
        "\n",
        "# Load official test.csv and find closest images\n",
        "test_coords_df = pd.read_csv(DRIVE_PATH / \"test.csv\", names=['RA', 'DEC'])\n",
        "_, indices = kdtree.query(test_coords_df[['RA', 'DEC']].values)\n",
        "test_files_to_load = img_df.iloc[indices]['image_path'].tolist()\n",
        "\n",
        "# Create DataLoader and run inference\n",
        "inference_tf = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
        "test_dataset = InferenceDataset(test_files_to_load, transform=inference_tf)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "class_to_idx = {name: i for i, name in enumerate(CLASSES)}\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, _ in tqdm(test_loader, desc=\"Predicting on Test Set\"):\n",
        "        probs = torch.sigmoid(model(images.to(device))).cpu().numpy()\n",
        "        # NOTE: Using a simple 0.5 threshold here. You would ideally load your tuned thresholds.\n",
        "        preds_indices = np.where(probs > 0.5)[1]\n",
        "        for i in range(len(probs)):\n",
        "            preds_indices = np.where(probs[i] > 0.5)[0]\n",
        "            labels = [CLASSES[j] for j in preds_indices]\n",
        "            predictions.append(labels)\n",
        "\n",
        "# Format and save the submission file\n",
        "labels_df = pd.DataFrame([p + [None]*(5 - len(p)) for p in predictions]) # Pad to have enough columns\n",
        "submission_df = pd.concat([test_coords_df, labels_df], axis=1)\n",
        "submission_path = DRIVE_PATH / \"test_labels.csv\"\n",
        "submission_df.to_csv(submission_path, index=False, header=False)\n",
        "\n",
        "print(f\"test_labels.csv saved to {submission_path}\")"
      ],
      "metadata": {
        "id": "d51473NOfyUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Generating generated_labels.csv sanity check ---\")\n",
        "\n",
        "# Get list of all unlabeled files\n",
        "unlabeled_files = [str(f) for f in (DRIVE_PATH / \"unl/unl_PNG\").glob(\"*.png\")]\n",
        "unlabeled_dataset = InferenceDataset(unlabeled_files, transform=inference_tf)\n",
        "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Run inference\n",
        "results = []\n",
        "with torch.no_grad():\n",
        "    for images, paths in tqdm(unlabeled_loader, desc=\"Labeling All Unlabeled\"):\n",
        "        probs = torch.sigmoid(model(images.to(device))).cpu().numpy()\n",
        "        for i, p in enumerate(probs):\n",
        "            ra, dec = extract_coords_from_filename(Path(paths[i]).name)\n",
        "            labels = [CLASSES[j] for j in np.where(p > 0.5)[0]]\n",
        "            results.append([ra, dec] + labels)\n",
        "\n",
        "# Format and save the submission file\n",
        "results_df = pd.DataFrame(results)\n",
        "submission_path = DRIVE_PATH / \"generated_labels.csv\"\n",
        "results_df.to_csv(submission_path, index=False, header=False)\n",
        "\n",
        "print(f\"generated_labels.csv saved to {submission_path}\")"
      ],
      "metadata": {
        "id": "KVQVwfDef3pt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}