{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kamohelo99/C0S711_Assignment_3/blob/Ndumiso/supervised_Only_on_human_labeled_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bckr19dIDCgg",
      "metadata": {
        "id": "bckr19dIDCgg"
      },
      "source": [
        "# Supervised Training Template\n",
        "\n",
        "This notebook outlines the steps required to train a convolutional neural network on the labelled MGCLS dataset. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dEZzbBBiDCgt",
      "metadata": {
        "id": "dEZzbBBiDCgt"
      },
      "source": [
        "## 1. Set up environment\n",
        "\n",
        "Import of required libraries. Ensure you are using a GPU runtime (if available.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ePJ1cZVWDCgv",
      "metadata": {
        "id": "ePJ1cZVWDCgv"
      },
      "outputs": [],
      "source": [
        "# Install required libraries for this notebook\n",
        "!pip install -q iterative-stratification torchmetrics astropy\n",
        "\n",
        "# Standard Library Imports\n",
        "import os\n",
        "import re\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "# Core Data Science and ML Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from astropy.coordinates import SkyCoord\n",
        "from astropy import units as u\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
        "\n",
        "# Torchmetrics for Evaluation\n",
        "from torchmetrics import MetricCollection\n",
        "from torchmetrics.classification import MultilabelF1Score\n",
        "\n",
        "# Global Settings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "print(\"All required libraries are imported.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FRQ8iprbDCg0",
      "metadata": {
        "id": "FRQ8iprbDCg0"
      },
      "source": [
        "## 2. Define file paths\n",
        "\n",
        "Specify the locations of your extracted data and labels. Update these variables to point to the directories on your own system or Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oPyosU58DCg2",
      "metadata": {
        "id": "oPyosU58DCg2"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive to access your data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# TODO: set these paths appropriately, I save mine in MyDrive\n",
        "DRIVE_PATH = Path(\"/content/drive/MyDrive/assignmentdata\")\n",
        "DATA_DIR = DRIVE_PATH / \"data\"\n",
        "LABELS_FILE = DRIVE_PATH / \"labels.csv\"\n",
        "\n",
        "# directories for generated files\n",
        "CHECKPOINT_DIR = DRIVE_PATH / \"checkpoints\"\n",
        "SPLIT_DIR = DRIVE_PATH / \"splits\"\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
        "SPLIT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# We will define num_classes dynamically after inspecting the data.\n",
        "num_classes = None\n",
        "\n",
        "print(f\"Data root set to: {DATA_DIR}\")\n",
        "print(\"Please ensure your data (labels.csv, typ/, exo/) is in this directory.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mqTBoXk_DCg3",
      "metadata": {
        "id": "mqTBoXk_DCg3"
      },
      "source": [
        "## 3. Load and inspect the labels\n",
        "\n",
        "Use of pandas to read `labels.csv` and explore its columns.  Identify the coordinate columns (e.g. `ra`, `dec`) and the label columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v4gIhAtRDCg5",
      "metadata": {
        "id": "v4gIhAtRDCg5"
      },
      "outputs": [],
      "source": [
        "# Read the labels CSV, providing column names as the file has no header\n",
        "labels_df = pd.read_csv(LABELS_FILE, names=['RA', 'DEC', 'L1', 'L2', 'L3', 'L4'])\n",
        "\n",
        "# Consolidate all label columns into a single 'labels' string\n",
        "label_cols = ['L1', 'L2', 'L3', 'L4']\n",
        "labels_df['labels'] = labels_df[label_cols].apply(lambda row: ', '.join(row.dropna().astype(str)), axis=1)\n",
        "\n",
        "print(\"Labels DataFrame:\")\n",
        "labels_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DirnG2LEDCg6",
      "metadata": {
        "id": "DirnG2LEDCg6"
      },
      "source": [
        "## 4. Implemention of coordinate parsing and label matching\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e46b382",
      "metadata": {
        "id": "8e46b382"
      },
      "outputs": [],
      "source": [
        "# combining the logic for coordinate parsing and matching.\n",
        "def extract_coords_from_filename(fname: str):\n",
        "    \"\"\"Extract RA/Dec from filename using a robust regex.\"\"\"\n",
        "    pattern = r\"([-+]?\\d*\\.\\d+|\\d+)\\s+([-+]?\\d*\\.\\d+|\\d+)_\"\n",
        "    m = re.search(pattern, fname)\n",
        "    if m:\n",
        "        try:\n",
        "            return float(m.group(1)), float(m.group(2))\n",
        "        except (ValueError, IndexError):\n",
        "            return None, None\n",
        "    return None, None\n",
        "\n",
        "def perform_matching(data_dir, labels_df):\n",
        "    \"\"\"Scans image folders, extracts coordinates, and matches them to labels using Astropy.\"\"\"\n",
        "    print(\"--- Starting Coordinate Matching ---\")\n",
        "\n",
        "    # Create an Astropy SkyCoord object for the catalog labels for fast matching\n",
        "    catalog = SkyCoord(ra=labels_df[\"RA\"].values*u.deg, dec=labels_df[\"DEC\"].values*u.deg, frame='icrs')\n",
        "\n",
        "    # Scan image folders ('typ' and 'exo')\n",
        "    imgs = []\n",
        "    for folder in [\"typ/typ_PNG\", \"exo/exo_PNG\"]:\n",
        "        folder_path = data_dir / folder\n",
        "        if not folder_path.exists(): continue\n",
        "        for fpath in folder_path.glob(\"*.png\"):\n",
        "            ra, dec = extract_coords_from_filename(fpath.name)\n",
        "            if ra is not None:\n",
        "                imgs.append({\"image_path\": str(fpath), \"RA_img\": ra, \"DEC_img\": dec})\n",
        "\n",
        "    images_df = pd.DataFrame(imgs)\n",
        "    print(f\"Found {len(images_df)} PNG files with valid coordinates.\")\n",
        "\n",
        "    # Use Astropy to find the nearest neighbor in the catalog for each image\n",
        "    image_coords = SkyCoord(ra=images_df[\"RA_img\"].values*u.deg, dec=images_df[\"DEC_img\"].values*u.deg, frame='icrs')\n",
        "    idx, sep2d, _ = image_coords.match_to_catalog_sky(catalog)\n",
        "\n",
        "    # Combine the matched data into a single DataFrame\n",
        "    matched_labels = labels_df.iloc[idx].reset_index(drop=True)\n",
        "    combined_df = pd.concat([images_df, matched_labels], axis=1)\n",
        "    combined_df['distance_arcsec'] = sep2d.arcsec\n",
        "\n",
        "    print(\"Matching complete.\")\n",
        "    return combined_df\n",
        "\n",
        "# Execute the matching process\n",
        "combined_data_df = perform_matching(DRIVE_PATH, labels_df)\n",
        "\n",
        "print(\"\\n--- Matched Data Sample ---\")\n",
        "combined_data_df.head()\n"
      ]
    },
    {
<<<<<<< HEAD
      "cell_type": "code",
      "execution_count": null,
      "id": "a605d995",
      "metadata": {
        "id": "a605d995"
      },
      "outputs": [],
      "source": [
        "# def match_labels(coords, labels_df, tol_arcsec=1.0):\n",
        "#     \"\"\"\n",
        "#     Match image coords (RA, Dec) to a row in labels_df using a tolerance in arcseconds.\n",
        "#     Returns: list of class label strings\n",
        "#     \"\"\"\n",
        "#     import numpy as np\n",
        "\n",
        "#     ra, dec = coords\n",
        "#     # Convert to numpy for vectorized diff\n",
        "#     ra_diff = np.abs(labels_df['ra'].values - ra)\n",
        "#     dec_diff = np.abs(labels_df['dec'].values - dec)\n",
        "\n",
        "#     # Angular tolerance in degrees\n",
        "#     tol_deg = tol_arcsec / 3600.0\n",
        "\n",
        "#     matches = (ra_diff < tol_deg) & (dec_diff < tol_deg)\n",
        "#     if not matches.any():\n",
        "#         return []\n",
        "\n",
        "#     matched_row = labels_df[matches].iloc[0]\n",
        "#     label_str = matched_row['labels']  # assumed comma-separated string\n",
        "#     return [l.strip() for l in label_str.split(',') if l.strip()]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2LaqQivCDChA",
      "metadata": {
        "id": "2LaqQivCDChA"
      },
      "outputs": [],
      "source": [
        "# # Load labels.csv\n",
        "# labels_df = pd.read_csv('data/labels.csv')\n",
        "\n",
        "# # Test with a file from 'typ/'\n",
        "# filename = os.listdir('data/typ')[0]\n",
        "# coords = parse_coords_from_filename(filename)\n",
        "# labels = match_labels(coords, labels_df)\n",
        "\n",
        "# print(\"Filename:\", filename)\n",
        "# print(\"Coordinates:\", coords)\n",
        "# print(\"Labels:\", labels)"
      ]
    },
    {
=======
>>>>>>> e2e93426140812564b11a155d6b82beff2bc7ec7
      "cell_type": "markdown",
      "id": "G9gkonnuDChB",
      "metadata": {
        "id": "G9gkonnuDChB"
      },
      "source": [
        "## 5. Create the dataset and dataloaders\n",
        "\n",
        "Here we instantiate the `RadioDataset` for the labelled images.  You may choose to combine the typical and exotic datasets or create separate datasets and use `ConcatDataset`.  Apply appropriate transformations (e.g. resizing, normalisation, augmentation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zN3pWlfYDChC",
      "metadata": {
        "id": "zN3pWlfYDChC"
      },
      "outputs": [],
      "source": [
        "# Define Transformations\n",
        "IMG_SIZE = 128 # Using the size from Kamo\n",
        "train_tf = transforms.Compose([\n",
        "    transforms.RandomRotation(360),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
        "])\n",
        "val_tf = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
        "])\n",
        "\n",
        "# Create Stratified Splits\n",
        "print(\"--- Creating Multilabel Stratified Splits ---\")\n",
        "combined_data_df[\"labels_list\"] = combined_data_df[\"labels\"].astype(str).apply(\n",
        "    lambda s: [lbl.strip() for lbl in s.split(\",\") if lbl.strip()]\n",
        ")\n",
        "mlb = MultiLabelBinarizer()\n",
        "y = mlb.fit_transform(combined_data_df[\"labels_list\"])\n",
        "CLASSES = mlb.classes_.tolist()\n",
        "num_classes = len(CLASSES)\n",
        "print(f\"Found {num_classes} unique classes: {CLASSES}\")\n",
        "\n",
        "# 70/30 split for train and validation\n",
        "msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=SEED)\n",
        "train_idx, val_idx = next(msss.split(combined_data_df, y))\n",
        "\n",
        "train_df = combined_data_df.iloc[train_idx]\n",
        "val_df = combined_data_df.iloc[val_idx]\n",
        "print(f\"Split complete. Train size: {len(train_df)}, Validation size: {len(val_df)}\")\n",
        "\n",
        "# Define the Dataset Class\n",
        "class RadioDataset(Dataset):\n",
        "    def __init__(self, df, classes, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "        self.mlb = MultiLabelBinarizer(classes=classes)\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img = Image.open(row['image_path']).convert('L') # Force 1-channel\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        labels_one_hot = self.mlb.fit_transform([row['labels_list']])[0]\n",
        "        labels = torch.tensor(labels_one_hot, dtype=torch.float32)\n",
        "        return img, labels\n",
        "\n",
        "# Instantiate Datasets and DataLoaders\n",
        "train_dataset = RadioDataset(train_df, classes=CLASSES, transform=train_tf)\n",
        "val_dataset = RadioDataset(val_df, classes=CLASSES, transform=val_tf)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(\"Datasets and DataLoaders are ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DXlfW4HMDChD",
      "metadata": {
        "id": "DXlfW4HMDChD"
      },
      "source": [
        "## 6. Build the model\n",
        "\n",
        "Create a ResNet‑based classifier using the helper function `build_model()` in `src/model.py`.  Remember to pass `num_classes` equal to the total number of labels you have.  Move the model to GPU if available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-zVqChRgDChE",
      "metadata": {
        "id": "-zVqChRgDChE"
      },
      "outputs": [],
      "source": [
        "def build_adapted_model(model_name=\"efficientnet_b0\", num_classes=num_classes):\n",
        "    \"\"\"Adapts a pre-trained model for 1-channel input and our classification task.\"\"\"\n",
        "    model = models.get_model(model_name, weights='IMAGENET1K_V1')\n",
        "\n",
        "    # Adapt first conv layer for 1-channel input\n",
        "    conv_layer = model.features[0][0]\n",
        "    new_conv = nn.Conv2d(1, conv_layer.out_channels,\n",
        "                         kernel_size=conv_layer.kernel_size, stride=conv_layer.stride,\n",
        "                         padding=conv_layer.padding, bias=conv_layer.bias is not None)\n",
        "    new_conv.weight.data = conv_layer.weight.data.mean(dim=1, keepdim=True)\n",
        "    model.features[0][0] = new_conv\n",
        "\n",
        "    # Adapt final classifier\n",
        "    in_features = model.classifier[1].in_features\n",
        "    model.classifier = nn.Sequential(nn.Dropout(p=0.3), nn.Linear(in_features, num_classes))\n",
        "\n",
        "    print(f\"Adapted {model_name} for 1-channel input and {num_classes} classes.\")\n",
        "    return model\n",
        "\n",
        "# Instantiate the model\n",
        "model = build_adapted_model(num_classes=num_classes)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "print(f\"Model moved to device: {device}\")\n",
        "\n",
        "# Define loss function and optimiser\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "M2IWQPRnDChF",
      "metadata": {
        "id": "M2IWQPRnDChF"
      },
      "source": [
        "## 7. Training loop\n",
        "For each batch, the list of label strings is converted into a multi‑hot tensor. Backpropagation is to optimise the model weights to improve the loss.  At the end of each epoch, The model is evaluated on the validation set and compute metrics i.e precision , recall, F1 and mAP using functions from `src/utils.py`. The best model is saved after the training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DhaF2ReADChG",
      "metadata": {
        "id": "DhaF2ReADChG"
      },
      "outputs": [],
      "source": [
        "# Define the evaluation loop logic\n",
        "def evaluate_epoch(model, loader, device, metrics_collection):\n",
        "    model.eval()\n",
        "    metrics_collection.reset()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            metrics_collection.update(outputs, labels.int())\n",
        "    return metrics_collection.compute()\n",
        "\n",
        "# Main Training Loop\n",
        "num_epochs = 50\n",
        "best_f1 = 0.0\n",
        "metrics = MetricCollection({'MacroF1': MultilabelF1Score(num_labels=num_classes, average='macro')}).to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    for images, labels in pbar:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        pbar.set_postfix(loss=running_loss/len(pbar))\n",
        "\n",
        "    # Validation\n",
        "    val_metrics = evaluate_epoch(model, val_loader, device, metrics)\n",
        "    val_f1 = val_metrics['MacroF1'].item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} Summary: Train Loss: {running_loss/len(train_loader):.4f}, Val MacroF1: {val_f1:.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_f1 > best_f1:\n",
        "        best_f1 = val_f1\n",
        "        torch.save(model.state_dict(), CHECKPOINT_DIR / 'supervised_best_model.pth')\n",
        "        print(f'New best model saved with F1-score: {best_f1:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KdEvawhJDChI",
      "metadata": {
        "id": "KdEvawhJDChI"
      },
      "source": [
        "## 8. Save the model\n",
        "\n",
        "Model is saved to disk to and will be used in semi-supervised learning section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4Y2xpAGSDChI",
      "metadata": {
        "id": "4Y2xpAGSDChI"
      },
      "outputs": [],
      "source": [
        "# The training loop already saves the BEST model.\n",
        "# the FINAL model after the last epoch.\n",
        "final_model_path = CHECKPOINT_DIR / 'supervised_final_model.pth'\n",
        "torch.save(model.state_dict(), final_model_path)\n",
        "print(f\"Training finished. Final model state saved to: {final_model_path}\")\n",
        "print(f\"The best performing model was saved to: {CHECKPOINT_DIR / 'supervised_best_model.pth'}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
