{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kamohelo99/C0S711_Assignment_3/blob/Ndumiso/semi_supervised_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUNoHGMdDeuz"
      },
      "source": [
        "# Semi‑Supervised Training\n",
        "\n",
        "The model uses the previously trained super-vised learning model to leverage unlabelled images using pseudo‑labelling and consistency regularisation.\n"
      ],
      "id": "fUNoHGMdDeuz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5l14pybDevC"
      },
      "source": [
        "## 1. Setup\n",
        "\n",
        "Import necessary modules and define file paths for labelled data, unlabelled data, the labels CSV, and the supervised model checkpoint."
      ],
      "id": "X5l14pybDevC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBHEzSOBDevF"
      },
      "outputs": [],
      "source": [
        "!pip install -q iterative-stratification torchmetrics astropy\n",
        "import os\n",
        "import re\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
        "\n",
        "from torchmetrics import MetricCollection\n",
        "from torchmetrics.classification import MultilabelF1Score\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# TODO: add data in these paths\n",
        "DRIVE_PATH = Path(\"/content/drive/MyDrive/assignmentdata\")\n",
        "DATA_DIR = DRIVE_PATH / \"data\"\n",
        "CHECKPOINT_DIR = DRIVE_PATH / \"checkpoints\"\n",
        "SPLIT_DIR = DRIVE_PATH / \"splits\"\n",
        "\n",
        "# Path to the unlabeled images\n",
        "unl_root = DRIVE_PATH / 'unl/unl_PNG'\n",
        "\n",
        "# Path to the model trained in the supervised notebook\n",
        "supervised_ckpt = CHECKPOINT_DIR / 'supervised_best_model.pth'\n",
        "\n",
        "# We will load num_classes and the class names from the files created by the first notebook\n",
        "CLASSES = ['Bent', 'Exotic', 'FR I', 'FR II', 'Point Source', 'S/Z shaped', 'Should be discarded', 'X-Shaped', 'typical']\n",
        "num_classes = len(CLASSES)\n",
        "\n",
        "print(f\"Found {num_classes} classes: {CLASSES}\")\n",
        "print(f\"Supervised model checkpoint path: {supervised_ckpt}\")\n"
      ],
      "id": "NBHEzSOBDevF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K98osfjcDevL"
      },
      "source": [
        "## 2. Load datasets and model\n",
        "\n",
        "We load the labelled dataset (typical and exotic images) and the unlabelled dataset.  We also instantiate the same network architecture and load the weights from the supervised training stage."
      ],
      "id": "K98osfjcDevL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35tWrmrlDevN"
      },
      "outputs": [],
      "source": [
        "# Define Model Architecture (must match the supervised model)\n",
        "def build_adapted_model(model_name=\"efficientnet_b0\", num_classes=num_classes):\n",
        "    \"\"\"Adapts a pre-trained model for 1-channel input.\"\"\"\n",
        "    model = models.get_model(model_name, weights='IMAGENET1K_V1')\n",
        "    conv_layer = model.features[0][0]\n",
        "    new_conv = nn.Conv2d(1, conv_layer.out_channels,\n",
        "                         kernel_size=conv_layer.kernel_size, stride=conv_layer.stride,\n",
        "                         padding=conv_layer.padding, bias=conv_layer.bias is not None)\n",
        "    new_conv.weight.data = conv_layer.weight.data.mean(dim=1, keepdim=True)\n",
        "    model.features[0][0] = new_conv\n",
        "    in_features = model.classifier[1].in_features\n",
        "    model.classifier = nn.Sequential(nn.Dropout(p=0.3), nn.Linear(in_features, num_classes))\n",
        "    return model\n",
        "\n",
        "# Define Transformations\n",
        "IMG_SIZE = 128\n",
        "inference_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
        "])\n",
        "\n",
        "# Define Unlabeled Dataset Class\n",
        "class UnlabeledDataset(Dataset):\n",
        "    def __init__(self, folder_path, transform=None):\n",
        "        self.files = sorted(list(Path(folder_path).glob(\"*.png\")))\n",
        "        self.transform = transform\n",
        "    def __len__(self): return len(self.files)\n",
        "    def __getitem__(self, idx):\n",
        "        fpath = self.files[idx]\n",
        "        img = Image.open(fpath).convert('L')\n",
        "        if self.transform: img = self.transform(img)\n",
        "        return img, str(fpath) # Return image and its path\n",
        "\n",
        "# Instantiate Unlabeled Dataset and DataLoader\n",
        "unlabelled_dataset = UnlabeledDataset(unl_root, transform=inference_transform)\n",
        "unlabelled_loader = DataLoader(unlabelled_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "print(f\"Found {len(unlabelled_dataset)} unlabeled images.\")\n",
        "\n",
        "# Load Model and Supervised Weights\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = build_adapted_model(num_classes=num_classes)\n",
        "if supervised_ckpt.exists():\n",
        "    model.load_state_dict(torch.load(supervised_ckpt, map_location=device))\n",
        "    print(f\"Successfully loaded supervised weights from {supervised_ckpt.name}\")\n",
        "else:\n",
        "    print(f\"WARNING: Supervised checkpoint not found at {supervised_ckpt}. Model has random weights.\")\n",
        "model = model.to(device)"
      ],
      "id": "35tWrmrlDevN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC21vhqCDevP"
      },
      "source": [
        "## 3. Generate pseudo‑labels\n",
        "\n",
        "Use the supervised model to infer labels for the unlabelled dataset.  For each image, compute the sigmoid output and assign labels for classes whose probabilities exceed a confidence threshold (e.g. 0.95).  You must define a mapping between class indices and label names (`class_names`)."
      ],
      "id": "YC21vhqCDevP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhKedmYdDevR"
      },
      "outputs": [],
      "source": [
        "# The class_names are already loaded as `CLASSES` from our classes.txt file.\n",
        "class_names = CLASSES\n",
        "class_to_idx = {name: i for i, name in enumerate(class_names)}\n",
        "\n",
        "confidence_threshold = 0.90 # Using a slightly lower threshold to get more labels\n",
        "margin_threshold = 0.2     # For FR I/II mutual exclusivity\n",
        "\n",
        "# Dictionary to store pseudo-labels keyed by image path\n",
        "pseudo_labels = {}\n",
        "\n",
        "print(f\"Generating pseudo-labels with confidence > {confidence_threshold}\")\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, paths in tqdm(unlabelled_loader, desc=\"Generating Pseudo-Labels\"):\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        probs = torch.sigmoid(outputs)\n",
        "\n",
        "        for i in range(len(paths)):\n",
        "            prob_vec = probs[i].cpu().numpy()\n",
        "\n",
        "            # Select labels that pass the high confidence threshold\n",
        "            pos_indices = np.where(prob_vec >= confidence_threshold)[0]\n",
        "            labels_for_img = [class_names[j] for j in pos_indices]\n",
        "\n",
        "            # Apply FR I/II mutual exclusivity rule\n",
        "            if 'FR I' in labels_for_img and 'FR II' in labels_for_img:\n",
        "                fr1_prob = prob_vec[class_to_idx['FR I']]\n",
        "                fr2_prob = prob_vec[class_to_idx['FR II']]\n",
        "                if abs(fr1_prob - fr2_prob) < margin_threshold:\n",
        "                    labels_for_img.remove('FR I')\n",
        "                    labels_for_img.remove('FR II')\n",
        "                elif fr1_prob > fr2_prob:\n",
        "                    labels_for_img.remove('FR II')\n",
        "                else:\n",
        "                    labels_for_img.remove('FR I')\n",
        "\n",
        "            if labels_for_img: # Only add if there are any labels left\n",
        "                pseudo_labels[paths[i]] = labels_for_img\n",
        "\n",
        "print(f\"\\nGenerated {len(pseudo_labels)} pseudo-labels for the unlabeled set.\")\n",
        "\n",
        "# Inspect a few pseudo-labels\n",
        "print(\"\\nSample Pseudo-Labels\")\n",
        "for path, labels in list(pseudo_labels.items())[:5]:\n",
        "    print(f\"{Path(path).name}: {labels}\")\n",
        "\n",
        "# Save the pseudo-labels to a file for reuse\n",
        "pseudo_labels_df = pd.DataFrame(pseudo_labels.items(), columns=['image_path', 'labels_list'])\n",
        "pseudo_labels_df.to_csv(SPLIT_DIR / \"pseudo_labels.csv\", index=False)\n",
        "print(f\"\\nPseudo-labels saved to {SPLIT_DIR / 'pseudo_labels.csv'}\")\n"
      ],
      "id": "DhKedmYdDevR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCxk485YDevT"
      },
      "source": [
        "## 4. Create a combined dataset\n",
        "\n",
        "To train on both labelled and pseudo‑labelled data, you need a dataset that returns a multi‑hot vector for each image.  Extend the `RadioDataset` class or write a new dataset class that looks up pseudo‑labels in the dictionary created above (for unlabelled images) and uses true labels for the labelled images.  Then concatenate the two datasets."
      ],
      "id": "SCxk485YDevT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0QCPeKpDevV"
      },
      "outputs": [],
      "source": [
        "# Define the Dataset Class for Combined Data\n",
        "# We will use the same dataset class from the supervised notebook, as it's already compatible.\n",
        "class RadioDataset(Dataset):\n",
        "    def __init__(self, df, classes, transform=None, is_pseudo=False):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "        self.mlb = MultiLabelBinarizer(classes=classes)\n",
        "        self.is_pseudo = is_pseudo\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img = Image.open(row['image_path']).convert('L')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        labels_one_hot = self.mlb.fit_transform([row['labels_list']])[0]\n",
        "        labels = torch.tensor(labels_one_hot, dtype=torch.float32)\n",
        "        # Apply lower weight for pseudo-labeled samples\n",
        "        weight = 0.6 if self.is_pseudo else 1.0\n",
        "        return img, labels, torch.tensor(weight, dtype=torch.float32)\n",
        "\n",
        "# Load the Original Labeled Data and New Pseudo-Labeled Data\n",
        "train_df_manual = pd.read_csv(SPLIT_DIR / \"train.csv\")\n",
        "train_df_manual[\"labels_list\"] = train_df_manual[\"labels\"].astype(str).apply(\n",
        "    lambda s: [lbl.strip() for lbl in s.split(\",\") if lbl.strip()]\n",
        ")\n",
        "\n",
        "# Convert the pseudo-labels dictionary back to a DataFrame with the right format\n",
        "pseudo_df = pd.DataFrame(pseudo_labels.items(), columns=['image_path', 'labels_list'])\n",
        "\n",
        "# Instantiate the Datasets\n",
        "train_tf = transforms.Compose([\n",
        "    transforms.RandomRotation(360),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
        "])\n",
        "manual_dataset = RadioDataset(train_df_manual, classes=CLASSES, transform=train_tf, is_pseudo=False)\n",
        "pseudo_dataset = RadioDataset(pseudo_df, classes=CLASSES, transform=train_tf, is_pseudo=True)\n",
        "\n",
        "# Concatenate and Create Final DataLoader\n",
        "combined_dataset = ConcatDataset([manual_dataset, pseudo_dataset])\n",
        "combined_loader = DataLoader(combined_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "print(f\"Created a combined dataset:\")\n",
        "print(f\"  - Manual (Human) Labels: {len(manual_dataset)}\")\n",
        "print(f\"  - Pseudo (Generated) Labels: {len(pseudo_dataset)}\")\n",
        "print(f\"  - Total Training Samples: {len(combined_dataset)}\")\n"
      ],
      "id": "t0QCPeKpDevV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "444zBCKyDevW"
      },
      "source": [
        "## 5. Fine‑tuning loop (e.g. FixMatch)\n",
        "\n",
        "Implement the semi‑supervised training loop.  For example, using FixMatch:\n",
        "\n",
        "- For each unlabelled image, create a weakly augmented and a strongly augmented version.\n",
        "- Use the model to produce pseudo‑labels from the weak view and enforce that the model’s prediction on the strong view matches these pseudo‑labels.\n",
        "- Combine this unsupervised loss with the supervised loss on labelled data.\n",
        "\n",
        "Below is a skeleton structure.  You must fill in the details for augmentation, loss computation, and parameter updates."
      ],
      "id": "444zBCKyDevW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6Rjbs6VDevZ"
      },
      "outputs": [],
      "source": [
        "# We will implement the Self-Training approach, which is simpler than FixMatch\n",
        "# and directly matches our project plan. The core idea is to retrain the model\n",
        "# on the combined dataset with weighted loss.\n",
        "\n",
        "# Re-initialize the Model\n",
        "# We start from scratch to see the full benefit of the larger dataset.\n",
        "model = build_adapted_model(num_classes=num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "# Define Optimizer and Loss\n",
        "# We use a weighted loss function.\n",
        "criterion = torch.nn.BCEWithLogitsLoss(reduction='none') # 'none' is crucial for weighting\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "metrics = MetricCollection({'MacroF1': MultilabelF1Score(num_labels=num_classes, average='macro')}).to(device)\n",
        "\n",
        "# Define Validation Set\n",
        "val_df = pd.read_csv(SPLIT_DIR / \"val.csv\")\n",
        "val_df[\"labels_list\"] = val_df[\"labels\"].astype(str).apply(\n",
        "    lambda s: [lbl.strip() for lbl in s.split(\",\") if lbl.strip()]\n",
        ")\n",
        "val_tf = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
        "])\n",
        "val_dataset = RadioDataset(val_df, classes=CLASSES, transform=val_tf)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Fine-tuning Loop\n",
        "num_epochs = 50\n",
        "best_f1 = 0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    pbar = tqdm(combined_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    for images, labels, weights in pbar:\n",
        "        images, labels, weights = images.to(device), labels.to(device), weights.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculate unweighted loss per sample\n",
        "        unweighted_loss = criterion(outputs, labels)\n",
        "\n",
        "        # Apply sample weights and calculate the mean loss for the batch\n",
        "        weighted_loss = (unweighted_loss * weights.view(-1, 1)).mean()\n",
        "\n",
        "        weighted_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += weighted_loss.item()\n",
        "        pbar.set_postfix(loss=running_loss/len(pbar))\n",
        "\n",
        "    # Validation (using the helper function from the supervised notebook)\n",
        "    def evaluate_epoch(model, loader, device, metrics_collection):\n",
        "        model.eval()\n",
        "        metrics_collection.reset()\n",
        "        with torch.no_grad():\n",
        "            for images, labels, _ in loader: # We ignore weight during validation\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                metrics_collection.update(outputs, labels.int())\n",
        "        return metrics_collection.compute()\n",
        "\n",
        "    val_metrics = evaluate_epoch(model, val_loader, device, metrics)\n",
        "    val_f1 = val_metrics['MacroF1'].item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} Summary: Train Loss: {running_loss/len(combined_loader):.4f}, Val MacroF1: {val_f1:.4f}\")\n",
        "\n",
        "    if val_f1 > best_f1:\n",
        "        best_f1 = val_f1\n",
        "        torch.save(model.state_dict(), CHECKPOINT_DIR / 'semi_supervised_best_model.pth')\n",
        "        print(f'New best semi-supervised model saved with F1-score: {best_f1:.4f}')\n",
        "\n",
        "# Save the final model\n",
        "torch.save(model.state_dict(), CHECKPOINT_DIR / 'semi_supervised_final_model.pth')\n",
        "print(f\"Training finished. Final semi-supervised model saved.\")"
      ],
      "id": "k6Rjbs6VDevZ"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}